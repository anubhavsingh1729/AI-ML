{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nfrom torchvision import datasets, transforms\nfrom torch.utils.data import DataLoader\nfrom PIL import Image\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch\nimport torchvision.models as models\nimport torchvision.models.segmentation as segmentation\nfrom torchmetrics.classification import MulticlassJaccardIndex as IoULoss\nfrom tqdm.notebook import tqdm\nfrom datetime import date\nimport sys\nimport numpy as np","metadata":{"execution":{"iopub.status.busy":"2024-02-26T11:25:03.695024Z","iopub.execute_input":"2024-02-26T11:25:03.695380Z","iopub.status.idle":"2024-02-26T11:25:11.072907Z","shell.execute_reply.started":"2024-02-26T11:25:03.695350Z","shell.execute_reply":"2024-02-26T11:25:11.071951Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"transform = transforms.Compose([\n    transforms.ToTensor(),\n])","metadata":{"execution":{"iopub.status.busy":"2024-02-26T11:25:11.074709Z","iopub.execute_input":"2024-02-26T11:25:11.075101Z","iopub.status.idle":"2024-02-26T11:25:11.079444Z","shell.execute_reply.started":"2024-02-26T11:25:11.075075Z","shell.execute_reply":"2024-02-26T11:25:11.078545Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"labels = [0,7,8,19,20,24,26,33]\nnolabels = [x for x in range(-1,34) if x not in labels]","metadata":{"execution":{"iopub.status.busy":"2024-02-26T11:25:11.080465Z","iopub.execute_input":"2024-02-26T11:25:11.080739Z","iopub.status.idle":"2024-02-26T11:25:11.090941Z","shell.execute_reply.started":"2024-02-26T11:25:11.080715Z","shell.execute_reply":"2024-02-26T11:25:11.090135Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"class CustomDataset(datasets.ImageFolder):\n    def __init__(self, root,img_dir, mask_dir, transform=None):\n        self.root = root\n        self.img_dir = os.path.join(root,img_dir)\n        self.mask_dir = os.path.join(root,mask_dir)\n        self.city_dir = os.listdir(self.img_dir)\n        \n        self.transform = transform\n        self.images = []\n        self.masks = []\n        for city in self.city_dir:\n            city_img = os.path.join(self.img_dir,city)\n            city_mask = os.path.join(self.mask_dir,city)\n            \n            for file in os.listdir(city_img):\n                img_path = os.path.join(city_img,file)\n                mask_path = os.path.join(city_mask,file)\n                self.images.append(img_path)\n                self.masks.append(mask_path)\n                \n    def __getitem__(self, index):\n        img_path = self.images[index]\n        mask_path = self.masks[index].replace('_leftImg8bit.png', '_gtFine_labelIds.png')\n        image = Image.open(img_path).convert(\"RGB\").resize((256,256))\n        mask = Image.open(mask_path).convert(\"L\").resize((256,256))\n        mask = np.array(mask)\n        for i in nolabels:\n            mask[mask == i] = 0\n        mask[mask > 33] = 0\n        for i in range(1,len(labels)):\n            mask[mask == labels[i]] = i \n        if self.transform is not None:\n            image = self.transform(image)\n            mask = torch.from_numpy(mask)\n\n        return {'image':image, 'mask':mask}\n\n    def __len__(self):\n        return len(self.images)","metadata":{"execution":{"iopub.status.busy":"2024-02-26T11:25:11.092791Z","iopub.execute_input":"2024-02-26T11:25:11.093048Z","iopub.status.idle":"2024-02-26T11:25:11.104767Z","shell.execute_reply.started":"2024-02-26T11:25:11.093025Z","shell.execute_reply":"2024-02-26T11:25:11.103924Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"root = ''\nimage_dir = '/kaggle/input/images/leftImg8bit_trainvaltest/leftImg8bit/train' \nmask_dir = '/kaggle/input/image-segmentation/gtFine_trainvaltest/gtFine/train'\n\nval_img = \"/kaggle/input/images/leftImg8bit_trainvaltest/leftImg8bit/val\"\nval_mask = \"/kaggle/input/image-segmentation/gtFine_trainvaltest/gtFine/val\"\n\ndataset = CustomDataset(root,image_dir, mask_dir, transform)\ndata_loader = DataLoader(dataset, batch_size=32, shuffle=True)\nvaldata = CustomDataset(root,val_img,val_mask,transform)\nvalloader = DataLoader(valdata,batch_size=32,shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2024-02-26T11:25:11.105662Z","iopub.execute_input":"2024-02-26T11:25:11.105923Z","iopub.status.idle":"2024-02-26T11:25:12.087778Z","shell.execute_reply.started":"2024-02-26T11:25:11.105902Z","shell.execute_reply":"2024-02-26T11:25:12.087014Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"deeplab_model = segmentation.deeplabv3_resnet50(pretrained=False, num_classes=8, weights_backbone =  models.ResNet50_Weights.DEFAULT)\n\nclassifier = list(deeplab_model.classifier.children())\nclassifier.append(nn.Softmax(dim=1))\ndeeplab_model.classifier = nn.Sequential(*classifier)\n\n#os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:256\"\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ntorch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2024-02-26T11:25:12.088795Z","iopub.execute_input":"2024-02-26T11:25:12.089053Z","iopub.status.idle":"2024-02-26T11:25:14.224726Z","shell.execute_reply.started":"2024-02-26T11:25:12.089031Z","shell.execute_reply":"2024-02-26T11:25:14.223892Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-11ad3fa6.pth\n100%|██████████| 97.8M/97.8M [00:01<00:00, 88.9MB/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"# avg=[0,0,0,0,0,0,0,0]\n# for i in data_loader:\n#     masks = torch.flatten(i['mask']).to(torch.long)\n#     a=list(torch.bincount(masks).numpy())\n#     for j in range(8):\n#         avg[j]+=a[j]/sum(a)\n    ","metadata":{"execution":{"iopub.status.busy":"2024-02-26T11:25:14.225819Z","iopub.execute_input":"2024-02-26T11:25:14.226110Z","iopub.status.idle":"2024-02-26T11:25:14.230008Z","shell.execute_reply.started":"2024-02-26T11:25:14.226085Z","shell.execute_reply":"2024-02-26T11:25:14.229221Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"weights = np.array([0.54388354, 0.32192455, 0.05298849, 0.00495117, 0.00775358,\n       0.00951798, 0.05644199, 0.00253869])\nweights = [1 / (8 * i) for i in weights]\nweights = np.array(weights)/sum(weights)\n#weights = np.array(avg)/len(data_loader)\nloss_weights = torch.from_numpy(weights).float().to(device)","metadata":{"execution":{"iopub.status.busy":"2024-02-26T11:25:14.231190Z","iopub.execute_input":"2024-02-26T11:25:14.231477Z","iopub.status.idle":"2024-02-26T11:25:14.391423Z","shell.execute_reply.started":"2024-02-26T11:25:14.231454Z","shell.execute_reply":"2024-02-26T11:25:14.390465Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"num_classes = 8\n#batch_size = 5\nlearning_rate = 1e-4\nnum_epochs = 100\nweight_decay = 1e-5\n\n#criterion = IoULoss(num_classes = num_classes).to(device)#\ncriterion = nn.CrossEntropyLoss(weight=loss_weights)\noptimizer = optim.Adam(deeplab_model.parameters(), lr=learning_rate, weight_decay=weight_decay)\niou = IoULoss(num_classes=8).to(device)\n#scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\nnn.DataParallel(deeplab_model)\ndeeplab_model = deeplab_model.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-02-26T11:25:14.393059Z","iopub.execute_input":"2024-02-26T11:25:14.393445Z","iopub.status.idle":"2024-02-26T11:25:14.467492Z","shell.execute_reply.started":"2024-02-26T11:25:14.393411Z","shell.execute_reply":"2024-02-26T11:25:14.466614Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"best_iou = float('inf')\n# Training loop\nfor epoch in tqdm(range(num_epochs)):\n    t_loss = 0.0\n    deeplab_model.train()\n    for batch in tqdm(data_loader):\n        images = batch['image']\n        masks = batch['mask']\n        images, masks = images.to(device), masks.to(device)\n        optimizer.zero_grad()\n        outputs = deeplab_model(images)\n        #masks = masks.squeeze(1)\n        masks = masks.long()\n        loss = criterion(outputs['out'], masks)\n        t_loss += loss.item()\n        loss.backward()\n        optimizer.step()\n        \n    deeplab_model.eval()\n    total_loss = 0.0\n    total_iou = 0.0\n    with torch.no_grad():\n        for val_batch in tqdm(valloader):\n            val_images = val_batch['image'].to(device)\n            masks = val_batch['mask'].to(device)\n            outputs = deeplab_model(val_images)\n#             masks = masks.squeeze(1)\n            masks = masks.long()\n            #print(torch.argmax(outputs['out'],dim=1).size(),masks.size())\n            v_loss = criterion(outputs['out'], masks)\n            total_iou += float(iou(torch.argmax(outputs['out'], dim=1), masks))\n            total_loss += v_loss.item() * images.size(0)\n        avg_val_loss = total_loss / len(valloader.dataset)\n        avg_iou = total_iou/len(valloader.dataset)\n        if avg_iou < best_iou :\n            best_iou = avg_iou\n            print(f'Saving the model at Epoch [{epoch + 1}/{num_epochs}]')\n            torch.save(deeplab_model.state_dict(), 'deeplab_model.pth')\n        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {t_loss/len(data_loader.dataset)}, Val Loss: {avg_val_loss}, iou:{avg_iou}')","metadata":{"execution":{"iopub.status.busy":"2024-02-26T11:25:14.470444Z","iopub.execute_input":"2024-02-26T11:25:14.470786Z"},"trusted":true},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/100 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d2395cbe26e445309bc8a54fc24f7cb0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/93 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"be68602e2f0d4ed189347248e9511014"}},"metadata":{}}]}]}